{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-12-12 00:00:00-05:00</th>\n",
       "      <td>0.099058</td>\n",
       "      <td>0.099488</td>\n",
       "      <td>0.099058</td>\n",
       "      <td>0.099058</td>\n",
       "      <td>469033600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-15 00:00:00-05:00</th>\n",
       "      <td>0.094321</td>\n",
       "      <td>0.094321</td>\n",
       "      <td>0.093890</td>\n",
       "      <td>0.093890</td>\n",
       "      <td>175884800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-16 00:00:00-05:00</th>\n",
       "      <td>0.087429</td>\n",
       "      <td>0.087429</td>\n",
       "      <td>0.086998</td>\n",
       "      <td>0.086998</td>\n",
       "      <td>105728000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-17 00:00:00-05:00</th>\n",
       "      <td>0.089152</td>\n",
       "      <td>0.089582</td>\n",
       "      <td>0.089152</td>\n",
       "      <td>0.089152</td>\n",
       "      <td>86441600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-18 00:00:00-05:00</th>\n",
       "      <td>0.091737</td>\n",
       "      <td>0.092167</td>\n",
       "      <td>0.091737</td>\n",
       "      <td>0.091737</td>\n",
       "      <td>73449600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-30 00:00:00-04:00</th>\n",
       "      <td>219.190002</td>\n",
       "      <td>220.330002</td>\n",
       "      <td>216.119995</td>\n",
       "      <td>218.800003</td>\n",
       "      <td>41643800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-31 00:00:00-04:00</th>\n",
       "      <td>221.440002</td>\n",
       "      <td>223.820007</td>\n",
       "      <td>220.630005</td>\n",
       "      <td>222.080002</td>\n",
       "      <td>50036300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-01 00:00:00-04:00</th>\n",
       "      <td>224.369995</td>\n",
       "      <td>224.479996</td>\n",
       "      <td>217.020004</td>\n",
       "      <td>218.360001</td>\n",
       "      <td>62501000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-02 00:00:00-04:00</th>\n",
       "      <td>219.149994</td>\n",
       "      <td>225.600006</td>\n",
       "      <td>217.710007</td>\n",
       "      <td>219.860001</td>\n",
       "      <td>98480100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-05 00:00:00-04:00</th>\n",
       "      <td>199.139999</td>\n",
       "      <td>213.470001</td>\n",
       "      <td>196.210007</td>\n",
       "      <td>209.270004</td>\n",
       "      <td>117397952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11002 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Open        High         Low       Close  \\\n",
       "Date                                                                        \n",
       "1980-12-12 00:00:00-05:00    0.099058    0.099488    0.099058    0.099058   \n",
       "1980-12-15 00:00:00-05:00    0.094321    0.094321    0.093890    0.093890   \n",
       "1980-12-16 00:00:00-05:00    0.087429    0.087429    0.086998    0.086998   \n",
       "1980-12-17 00:00:00-05:00    0.089152    0.089582    0.089152    0.089152   \n",
       "1980-12-18 00:00:00-05:00    0.091737    0.092167    0.091737    0.091737   \n",
       "...                               ...         ...         ...         ...   \n",
       "2024-07-30 00:00:00-04:00  219.190002  220.330002  216.119995  218.800003   \n",
       "2024-07-31 00:00:00-04:00  221.440002  223.820007  220.630005  222.080002   \n",
       "2024-08-01 00:00:00-04:00  224.369995  224.479996  217.020004  218.360001   \n",
       "2024-08-02 00:00:00-04:00  219.149994  225.600006  217.710007  219.860001   \n",
       "2024-08-05 00:00:00-04:00  199.139999  213.470001  196.210007  209.270004   \n",
       "\n",
       "                              Volume  Dividends  Stock Splits  \n",
       "Date                                                           \n",
       "1980-12-12 00:00:00-05:00  469033600        0.0           0.0  \n",
       "1980-12-15 00:00:00-05:00  175884800        0.0           0.0  \n",
       "1980-12-16 00:00:00-05:00  105728000        0.0           0.0  \n",
       "1980-12-17 00:00:00-05:00   86441600        0.0           0.0  \n",
       "1980-12-18 00:00:00-05:00   73449600        0.0           0.0  \n",
       "...                              ...        ...           ...  \n",
       "2024-07-30 00:00:00-04:00   41643800        0.0           0.0  \n",
       "2024-07-31 00:00:00-04:00   50036300        0.0           0.0  \n",
       "2024-08-01 00:00:00-04:00   62501000        0.0           0.0  \n",
       "2024-08-02 00:00:00-04:00   98480100        0.0           0.0  \n",
       "2024-08-05 00:00:00-04:00  117397952        0.0           0.0  \n",
       "\n",
       "[11002 rows x 7 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "ticker = yf.Ticker('AAPL')\n",
    "ticker_history = ticker.history(period=\"max\")\n",
    "ticker_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ppiot\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │        \u001b[38;5;34m11,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m20,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,451</span> (122.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,451\u001b[0m (122.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,451</span> (122.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,451\u001b[0m (122.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 2687.4177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1dd8cda6710>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the create_sequences function\n",
    "def create_sequences(data, seq_length):\n",
    "    data_array = []\n",
    "    for i in range(len(data) - seq_length + 1):\n",
    "        seq = data[i:i+seq_length]\n",
    "        data_array.append(seq)\n",
    "    return np.array(data_array)\n",
    "\n",
    "# Assume ticker_history is a pandas DataFrame with the necessary columns\n",
    "# Add the Future Close column\n",
    "ticker_history.fillna(0, inplace=True)\n",
    "ticker_history['Future Close'] = ticker_history['Close'].shift(-1)\n",
    "\n",
    "# Create the datasets\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(ticker_history[['Open', 'High', 'Low', 'Close', 'Volume']])\n",
    "\n",
    "# Create the datasets\n",
    "appl_x_dataset = create_sequences(scaled_features, 50)\n",
    "\n",
    "# The target should be the 'Future Close' for each sequence\n",
    "appl_y_dataset = ticker_history['Future Close'].shift(-50).dropna()\n",
    "\n",
    "# Only keep the samples where 'Future Close' is not NaN\n",
    "appl_x_dataset = appl_x_dataset[:len(appl_y_dataset)]\n",
    "\n",
    "# Define the model\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.LSTM(50, activation='relu', input_shape=(50, 5), return_sequences=True))\n",
    "model.add(keras.layers.LSTM(50, activation='relu'))\n",
    "model.add(keras.layers.Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(appl_x_dataset, appl_y_dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 476.8351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1dd8ccf3c10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(appl_x_dataset, appl_y_dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 32.5495\n",
      "Epoch 2/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 29.0019\n",
      "Epoch 3/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 27.5008\n",
      "Epoch 4/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 24.5498\n",
      "Epoch 5/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 15107374080.0000\n",
      "Epoch 6/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 162.1394\n",
      "Epoch 7/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 2187.6370\n",
      "Epoch 8/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 27.5869\n",
      "Epoch 9/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 28.1710\n",
      "Epoch 10/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 27.8726\n",
      "Epoch 11/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 24.4836\n",
      "Epoch 12/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 24.5409\n",
      "Epoch 13/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 27.4689\n",
      "Epoch 14/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 25.4982\n",
      "Epoch 15/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 24.3576\n",
      "Epoch 16/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 24.0512\n",
      "Epoch 17/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 24.6974\n",
      "Epoch 18/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 23.8847\n",
      "Epoch 19/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 24.2022\n",
      "Epoch 20/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 26.8155\n",
      "Epoch 21/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 3827.6804\n",
      "Epoch 22/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 22.9499\n",
      "Epoch 23/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 23.6559\n",
      "Epoch 24/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 21.8101\n",
      "Epoch 25/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 27.9014\n",
      "Epoch 26/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 22.8782\n",
      "Epoch 27/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 23.5579\n",
      "Epoch 28/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 23.0635\n",
      "Epoch 29/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 25.0803\n",
      "Epoch 30/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 23.0779\n",
      "Epoch 31/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 20.8978\n",
      "Epoch 32/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 25.6636\n",
      "Epoch 33/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 22.6693\n",
      "Epoch 34/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 983.4011\n",
      "Epoch 35/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 19.9787\n",
      "Epoch 36/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 21.0703\n",
      "Epoch 37/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 20.4960\n",
      "Epoch 38/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 18.2610\n",
      "Epoch 39/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 18.4184\n",
      "Epoch 40/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 18.8987\n",
      "Epoch 41/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 18.2702\n",
      "Epoch 42/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 20.0146\n",
      "Epoch 43/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 18.4475\n",
      "Epoch 44/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 17.4224\n",
      "Epoch 45/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 17.5222\n",
      "Epoch 46/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 16.3633\n",
      "Epoch 47/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 18.9025\n",
      "Epoch 48/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 19.5344\n",
      "Epoch 49/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 16.6508\n",
      "Epoch 50/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 19.6786\n",
      "Epoch 51/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 18.1975\n",
      "Epoch 52/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 18.2619\n",
      "Epoch 53/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 18.6609\n",
      "Epoch 54/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 23.3308\n",
      "Epoch 55/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 24.7683\n",
      "Epoch 56/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 20.4190\n",
      "Epoch 57/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 21.3687\n",
      "Epoch 58/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 21.5572\n",
      "Epoch 59/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 19.6297\n",
      "Epoch 60/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 17.1373\n",
      "Epoch 61/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 20.3279\n",
      "Epoch 62/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 17.5335\n",
      "Epoch 63/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 17.7457\n",
      "Epoch 64/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 17.8498\n",
      "Epoch 65/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 23.1250\n",
      "Epoch 66/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 15.1347\n",
      "Epoch 67/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 13.2713\n",
      "Epoch 68/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 12.1734\n",
      "Epoch 69/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 12.2830\n",
      "Epoch 70/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 13.0540\n",
      "Epoch 71/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 13.8762\n",
      "Epoch 72/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 9.1049\n",
      "Epoch 73/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 9.2217\n",
      "Epoch 74/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 11.1921\n",
      "Epoch 75/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 208583.8125\n",
      "Epoch 76/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 26.2513\n",
      "Epoch 77/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 24.0126\n",
      "Epoch 78/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 25.1972\n",
      "Epoch 79/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 22.2164\n",
      "Epoch 80/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 22.7669\n",
      "Epoch 81/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 22.3567\n",
      "Epoch 82/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 24.3457\n",
      "Epoch 83/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 25.4701\n",
      "Epoch 84/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 24.8423\n",
      "Epoch 85/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 26.2740\n",
      "Epoch 86/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 25.6313\n",
      "Epoch 87/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 25.1518\n",
      "Epoch 88/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 27.1169\n",
      "Epoch 89/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 23.1958\n",
      "Epoch 90/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 25.7552\n",
      "Epoch 91/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 22.5736\n",
      "Epoch 92/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 21.8720\n",
      "Epoch 93/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 23.1664\n",
      "Epoch 94/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 23.0542\n",
      "Epoch 95/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 21.3935\n",
      "Epoch 96/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 45.0522\n",
      "Epoch 97/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 26.2901\n",
      "Epoch 98/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 23.7939\n",
      "Epoch 99/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 25.1123\n",
      "Epoch 100/100\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 21.9163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1dd8f9698d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(appl_x_dataset, appl_y_dataset, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
